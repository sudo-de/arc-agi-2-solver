{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ARC-AGI Data Exploration\n",
    "\n",
    "# This notebook explores the ARC-AGI dataset to understand:\n",
    "# - Task structure and patterns\n",
    "# - Grid size distributions\n",
    "# - Color usage patterns\n",
    "# - Training vs test characteristics\n",
    "# - Visualization of example tasks\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "# ARC color mapping for visualization\n",
    "ARC_COLORS = {\n",
    "    0: '#000000',  # black\n",
    "    1: '#1E90FF',  # blue  \n",
    "    2: '#FF6347',  # red\n",
    "    3: '#32CD32',  # green\n",
    "    4: '#FFD700',  # yellow\n",
    "    5: '#A9A9A9',  # gray\n",
    "    6: '#FF1493',  # magenta\n",
    "    7: '#FF8C00',  # orange\n",
    "    8: '#87CEEB',  # sky blue\n",
    "    9: '#8B4513'   # brown\n",
    "}\n",
    "\n",
    "def plot_grid(grid, title=\"\", ax=None):\n",
    "    \"\"\"Plot an ARC grid with proper colors\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    \n",
    "    grid = np.array(grid)\n",
    "    \n",
    "    # Create color matrix\n",
    "    colored_grid = np.zeros((*grid.shape, 3))\n",
    "    for i in range(grid.shape[0]):\n",
    "        for j in range(grid.shape[1]):\n",
    "            color = ARC_COLORS[grid[i, j]]\n",
    "            colored_grid[i, j] = [int(color[1:3], 16)/255, int(color[3:5], 16)/255, int(color[5:7], 16)/255]\n",
    "    \n",
    "    ax.imshow(colored_grid, aspect='equal')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(grid.shape[0] + 1):\n",
    "        ax.axhline(i - 0.5, color='black', linewidth=0.5)\n",
    "    for j in range(grid.shape[1] + 1):\n",
    "        ax.axvline(j - 0.5, color='black', linewidth=0.5)\n",
    "\n",
    "def load_arc_data(split='training'):\n",
    "    \"\"\"Load ARC data from JSON files\"\"\"\n",
    "    try:\n",
    "        if split == 'training':\n",
    "            with open('/kaggle/input/arc-prize-2025/arc-agi_training_challenges.json', 'r') as f:\n",
    "                challenges = json.load(f)\n",
    "            with open('/kaggle/input/arc-prize-2025/arc-agi_training_solutions.json', 'r') as f:\n",
    "                solutions = json.load(f)\n",
    "        elif split == 'evaluation':\n",
    "            with open('/kaggle/input/arc-prize-2025/arc-agi_evaluation_challenges.json', 'r') as f:\n",
    "                challenges = json.load(f)\n",
    "            with open('/kaggle/input/arc-prize-2025/arc-agi_evaluation_solutions.json', 'r') as f:\n",
    "                solutions = json.load(f)\n",
    "        else:\n",
    "            with open('/kaggle/input/arc-prize-2025/arc-agi_test_challenges.json', 'r') as f:\n",
    "                challenges = json.load(f)\n",
    "            solutions = None\n",
    "        \n",
    "        print(f\"‚úì Loaded {len(challenges)} {split} challenges\")\n",
    "        return challenges, solutions\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚úó Could not load {split} data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "print(\"Data loading function defined\")\n",
    "\n",
    "# Load training data for exploration\n",
    "print(\"Loading ARC training data...\")\n",
    "training_challenges, training_solutions = load_arc_data('training')\n",
    "\n",
    "if training_challenges is None:\n",
    "    print(\"No training data found. Using sample data for demonstration.\")\n",
    "    # Create sample data structure\n",
    "    training_challenges = {\n",
    "        'sample_task_1': {\n",
    "            'train': [{\n",
    "                'input': [[0, 1], [1, 0]],\n",
    "                'output': [[1, 0], [0, 1]]\n",
    "            }],\n",
    "            'test': [{\n",
    "                'input': [[0, 2], [2, 0]]\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "    training_solutions = {\n",
    "        'sample_task_1': [[[2, 0], [0, 2]]]\n",
    "    }\n",
    "\n",
    "print(f\"Working with {len(training_challenges)} tasks\")\n",
    "\n",
    "# Analyze dataset statistics\n",
    "print(\"Analyzing dataset statistics...\")\n",
    "\n",
    "stats = {\n",
    "    'total_tasks': len(training_challenges),\n",
    "    'train_examples_per_task': [],\n",
    "    'test_examples_per_task': [],\n",
    "    'grid_sizes': [],\n",
    "    'colors_used': Counter(),\n",
    "    'unique_colors_per_grid': [],\n",
    "    'grid_transformations': [],\n",
    "    'input_output_size_relations': []\n",
    "}\n",
    "\n",
    "for task_id, task_data in training_challenges.items():\n",
    "    # Count examples\n",
    "    stats['train_examples_per_task'].append(len(task_data['train']))\n",
    "    stats['test_examples_per_task'].append(len(task_data['test']))\n",
    "    \n",
    "    # Analyze training examples\n",
    "    for example in task_data['train']:\n",
    "        input_grid = np.array(example['input'])\n",
    "        output_grid = np.array(example['output'])\n",
    "        \n",
    "        # Grid sizes\n",
    "        stats['grid_sizes'].append(('input', input_grid.shape))\n",
    "        stats['grid_sizes'].append(('output', output_grid.shape))\n",
    "        \n",
    "        # Colors\n",
    "        input_colors = set(input_grid.flatten())\n",
    "        output_colors = set(output_grid.flatten())\n",
    "        \n",
    "        for color in input_colors:\n",
    "            stats['colors_used'][color] += 1\n",
    "        for color in output_colors:\n",
    "            stats['colors_used'][color] += 1\n",
    "            \n",
    "        stats['unique_colors_per_grid'].append(len(input_colors))\n",
    "        stats['unique_colors_per_grid'].append(len(output_colors))\n",
    "        \n",
    "        # Size relationships\n",
    "        if input_grid.shape == output_grid.shape:\n",
    "            stats['input_output_size_relations'].append('same')\n",
    "        elif input_grid.size > output_grid.size:\n",
    "            stats['input_output_size_relations'].append('shrink')\n",
    "        else:\n",
    "            stats['input_output_size_relations'].append('grow')\n",
    "    \n",
    "    # Analyze test examples  \n",
    "    for example in task_data['test']:\n",
    "        input_grid = np.array(example['input'])\n",
    "        stats['grid_sizes'].append(('test_input', input_grid.shape))\n",
    "        \n",
    "        input_colors = set(input_grid.flatten())\n",
    "        for color in input_colors:\n",
    "            stats['colors_used'][color] += 1\n",
    "        stats['unique_colors_per_grid'].append(len(input_colors))\n",
    "\n",
    "print(\"Analysis complete!\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total tasks: {stats['total_tasks']}\")\n",
    "print(f\"Train examples per task: {np.mean(stats['train_examples_per_task']):.1f} ¬± {np.std(stats['train_examples_per_task']):.1f}\")\n",
    "print(f\"Test examples per task: {np.mean(stats['test_examples_per_task']):.1f} ¬± {np.std(stats['test_examples_per_task']):.1f}\")\n",
    "print(f\"Unique colors per grid: {np.mean(stats['unique_colors_per_grid']):.1f} ¬± {np.std(stats['unique_colors_per_grid']):.1f}\")\n",
    "\n",
    "# Grid size analysis\n",
    "grid_sizes = [size for _, size in stats['grid_sizes']]\n",
    "grid_areas = [size[0] * size[1] for size in grid_sizes]\n",
    "grid_widths = [size[1] for size in grid_sizes]\n",
    "grid_heights = [size[0] for size in grid_sizes]\n",
    "\n",
    "print(f\"\\nüìê GRID DIMENSIONS\")\n",
    "print(f\"Width range: {min(grid_widths)} - {max(grid_widths)} (avg: {np.mean(grid_widths):.1f})\")\n",
    "print(f\"Height range: {min(grid_heights)} - {max(grid_heights)} (avg: {np.mean(grid_heights):.1f})\")\n",
    "print(f\"Area range: {min(grid_areas)} - {max(grid_areas)} (avg: {np.mean(grid_areas):.1f})\")\n",
    "\n",
    "# Size relationships\n",
    "size_rel_counts = Counter(stats['input_output_size_relations'])\n",
    "print(f\"\\nüîÑ INPUT-OUTPUT SIZE RELATIONSHIPS\")\n",
    "for rel, count in size_rel_counts.items():\n",
    "    percentage = count / len(stats['input_output_size_relations']) * 100\n",
    "    print(f\"{rel}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('ARC-AGI Dataset Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Examples per task distribution\n",
    "axes[0, 0].hist(stats['train_examples_per_task'], bins=range(1, max(stats['train_examples_per_task'])+2), \n",
    "                alpha=0.7, label='Train', edgecolor='black')\n",
    "axes[0, 0].hist(stats['test_examples_per_task'], bins=range(1, max(stats['test_examples_per_task'])+2), \n",
    "                alpha=0.7, label='Test', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Examples per Task')\n",
    "axes[0, 0].set_ylabel('Number of Tasks')\n",
    "axes[0, 0].set_title('Examples per Task Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Grid size distribution\n",
    "axes[0, 1].scatter(grid_widths, grid_heights, alpha=0.6, s=20)\n",
    "axes[0, 1].set_xlabel('Grid Width')\n",
    "axes[0, 1].set_ylabel('Grid Height')\n",
    "axes[0, 1].set_title('Grid Size Distribution')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Color usage frequency\n",
    "colors = list(stats['colors_used'].keys())\n",
    "counts = list(stats['colors_used'].values())\n",
    "color_names = ['Black', 'Blue', 'Red', 'Green', 'Yellow', 'Gray', 'Magenta', 'Orange', 'Sky Blue', 'Brown']\n",
    "bars = axes[0, 2].bar(range(len(colors)), counts, \n",
    "                      color=[ARC_COLORS[c] for c in colors], \n",
    "                      edgecolor='black', linewidth=0.5)\n",
    "axes[0, 2].set_xlabel('ARC Colors')\n",
    "axes[0, 2].set_ylabel('Usage Frequency')\n",
    "axes[0, 2].set_title('Color Usage Distribution')\n",
    "axes[0, 2].set_xticks(range(len(colors)))\n",
    "axes[0, 2].set_xticklabels([f'{c}' for c in colors], rotation=45)\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Unique colors per grid\n",
    "axes[1, 0].hist(stats['unique_colors_per_grid'], bins=range(1, max(stats['unique_colors_per_grid'])+2), \n",
    "                alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Unique Colors per Grid')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Color Diversity Distribution')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Grid area distribution\n",
    "axes[1, 1].hist(grid_areas, bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Grid Area (pixels)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Grid Area Distribution')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Size relationship pie chart\n",
    "if stats['input_output_size_relations']:\n",
    "    size_rel_counts = Counter(stats['input_output_size_relations'])\n",
    "    labels = list(size_rel_counts.keys())\n",
    "    sizes = list(size_rel_counts.values())\n",
    "    axes[1, 2].pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1, 2].set_title('Input-Output Size Relationships')\n",
    "else:\n",
    "    axes[1, 2].text(0.5, 0.5, 'No size\\nrelationship\\ndata', \n",
    "                    ha='center', va='center', transform=axes[1, 2].transAxes)\n",
    "    axes[1, 2].set_title('Input-Output Size Relationships')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize example tasks\n",
    "def visualize_task(task_id, task_data, solutions=None, max_examples=3):\n",
    "    \"\"\"Visualize a complete ARC task with train/test examples\"\"\"\n",
    "    n_train = min(len(task_data['train']), max_examples)\n",
    "    n_test = min(len(task_data['test']), max_examples)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_train + n_test, 3, figsize=(12, 4*(n_train + n_test)))\n",
    "    if (n_train + n_test) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    fig.suptitle(f'Task: {task_id}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    row = 0\n",
    "    \n",
    "    # Training examples\n",
    "    for i in range(n_train):\n",
    "        example = task_data['train'][i]\n",
    "        \n",
    "        plot_grid(example['input'], f'Train {i+1} - Input', axes[row, 0])\n",
    "        plot_grid(example['output'], f'Train {i+1} - Output', axes[row, 1])\n",
    "        \n",
    "        # Transformation analysis\n",
    "        input_shape = np.array(example['input']).shape\n",
    "        output_shape = np.array(example['output']).shape\n",
    "        input_colors = len(set(np.array(example['input']).flatten()))\n",
    "        output_colors = len(set(np.array(example['output']).flatten()))\n",
    "        \n",
    "        transform_text = f\"Shape: {input_shape} ‚Üí {output_shape}\\n\"\n",
    "        transform_text += f\"Colors: {input_colors} ‚Üí {output_colors}\\n\"\n",
    "        \n",
    "        if input_shape == output_shape:\n",
    "            transform_text += \"Type: Same size\"\n",
    "        elif np.prod(input_shape) > np.prod(output_shape):\n",
    "            transform_text += \"Type: Shrinking\"\n",
    "        else:\n",
    "            transform_text += \"Type: Growing\"\n",
    "        \n",
    "        axes[row, 2].text(0.1, 0.5, transform_text, transform=axes[row, 2].transAxes, \n",
    "                         fontsize=10, verticalalignment='center',\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7))\n",
    "        axes[row, 2].set_xlim(0, 1)\n",
    "        axes[row, 2].set_ylim(0, 1)\n",
    "        axes[row, 2].set_xticks([])\n",
    "        axes[row, 2].set_yticks([])\n",
    "        axes[row, 2].set_title(f'Train {i+1} - Analysis')\n",
    "        \n",
    "        row += 1\n",
    "    \n",
    "    # Test examples\n",
    "    for i in range(n_test):\n",
    "        example = task_data['test'][i]\n",
    "        \n",
    "        plot_grid(example['input'], f'Test {i+1} - Input', axes[row, 0])\n",
    "        \n",
    "        # Show solution if available\n",
    "        if solutions and task_id in solutions and i < len(solutions[task_id]):\n",
    "            plot_grid(solutions[task_id][i], f'Test {i+1} - Solution', axes[row, 1])\n",
    "        else:\n",
    "            axes[row, 1].text(0.5, 0.5, '?', ha='center', va='center', \n",
    "                             transform=axes[row, 1].transAxes, fontsize=48,\n",
    "                             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "            axes[row, 1].set_xlim(0, 1)\n",
    "            axes[row, 1].set_ylim(0, 1)\n",
    "            axes[row, 1].set_xticks([])\n",
    "            axes[row, 1].set_yticks([])\n",
    "            axes[row, 1].set_title(f'Test {i+1} - Unknown')\n",
    "        \n",
    "        # Test analysis\n",
    "        input_shape = np.array(example['input']).shape\n",
    "        input_colors = len(set(np.array(example['input']).flatten()))\n",
    "        \n",
    "        test_text = f\"Input Shape: {input_shape}\\n\"\n",
    "        test_text += f\"Input Colors: {input_colors}\\n\"\n",
    "        test_text += \"Task: Apply learned rule\"\n",
    "        \n",
    "        axes[row, 2].text(0.1, 0.5, test_text, transform=axes[row, 2].transAxes, \n",
    "                         fontsize=10, verticalalignment='center',\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\", alpha=0.7))\n",
    "        axes[row, 2].set_xlim(0, 1)\n",
    "        axes[row, 2].set_ylim(0, 1)\n",
    "        axes[row, 2].set_xticks([])\n",
    "        axes[row, 2].set_yticks([])\n",
    "        axes[row, 2].set_title(f'Test {i+1} - Analysis')\n",
    "        \n",
    "        row += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show a few example tasks\n",
    "print(\"üéØ EXAMPLE TASK VISUALIZATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "task_ids = list(training_challenges.keys())[:3]  # Show first 3 tasks\n",
    "for task_id in task_ids:\n",
    "    print(f\"\\nVisualizing task: {task_id}\")\n",
    "    visualize_task(task_id, training_challenges[task_id], training_solutions)\n",
    "\n",
    "# Advanced pattern analysis\n",
    "print(\"üîç ADVANCED PATTERN ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def analyze_transformations(challenges):\n",
    "    \"\"\"Analyze common transformation patterns\"\"\"\n",
    "    patterns = {\n",
    "        'identity': 0,  # Input == Output\n",
    "        'rotation': 0,\n",
    "        'reflection': 0,\n",
    "        'color_change': 0,\n",
    "        'scaling': 0,\n",
    "        'complex': 0\n",
    "    }\n",
    "    \n",
    "    for task_id, task_data in challenges.items():\n",
    "        for example in task_data['train']:\n",
    "            input_grid = np.array(example['input'])\n",
    "            output_grid = np.array(example['output'])\n",
    "            \n",
    "            if np.array_equal(input_grid, output_grid):\n",
    "                patterns['identity'] += 1\n",
    "            elif input_grid.shape != output_grid.shape:\n",
    "                patterns['scaling'] += 1\n",
    "            elif np.array_equal(input_grid, np.rot90(output_grid, k=1)) or \\\n",
    "                 np.array_equal(input_grid, np.rot90(output_grid, k=2)) or \\\n",
    "                 np.array_equal(input_grid, np.rot90(output_grid, k=3)):\n",
    "                patterns['rotation'] += 1\n",
    "            elif np.array_equal(input_grid, np.fliplr(output_grid)) or \\\n",
    "                 np.array_equal(input_grid, np.flipud(output_grid)):\n",
    "                patterns['reflection'] += 1\n",
    "            elif input_grid.shape == output_grid.shape and \\\n",
    "                 not np.array_equal((input_grid > 0), (output_grid > 0)):\n",
    "                patterns['color_change'] += 1\n",
    "            else:\n",
    "                patterns['complex'] += 1\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "transformation_patterns = analyze_transformations(training_challenges)\n",
    "\n",
    "print(\"Transformation patterns found:\")\n",
    "total_examples = sum(transformation_patterns.values())\n",
    "for pattern, count in transformation_patterns.items():\n",
    "    percentage = count / total_examples * 100 if total_examples > 0 else 0\n",
    "    print(f\"{pattern}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize transformation patterns\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "patterns = list(transformation_patterns.keys())\n",
    "counts = list(transformation_patterns.values())\n",
    "\n",
    "bars = ax.bar(patterns, counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "ax.set_xlabel('Transformation Type')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Transformation Patterns')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "            f'{count}', ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate exploration summary report\n",
    "print(\"\\nüìã EXPLORATION SUMMARY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "report = f\"\"\"\n",
    "ARC-AGI Dataset Exploration Summary\n",
    "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "üìä DATASET OVERVIEW:\n",
    "‚Ä¢ Total tasks analyzed: {stats['total_tasks']}\n",
    "‚Ä¢ Average training examples per task: {np.mean(stats['train_examples_per_task']):.1f}\n",
    "‚Ä¢ Average test examples per task: {np.mean(stats['test_examples_per_task']):.1f}\n",
    "\n",
    "üìê GRID CHARACTERISTICS:\n",
    "‚Ä¢ Grid width range: {min(grid_widths)} - {max(grid_widths)} (avg: {np.mean(grid_widths):.1f})\n",
    "‚Ä¢ Grid height range: {min(grid_heights)} - {max(grid_heights)} (avg: {np.mean(grid_heights):.1f})\n",
    "‚Ä¢ Grid area range: {min(grid_areas)} - {max(grid_areas)} (avg: {np.mean(grid_areas):.1f})\n",
    "\n",
    "üé® COLOR USAGE:\n",
    "‚Ä¢ Most common color: {max(stats['colors_used'], key=stats['colors_used'].get)} (used {max(stats['colors_used'].values())} times)\n",
    "‚Ä¢ Least common color: {min(stats['colors_used'], key=stats['colors_used'].get)} (used {min(stats['colors_used'].values())} times)\n",
    "‚Ä¢ Average unique colors per grid: {np.mean(stats['unique_colors_per_grid']):.1f}\n",
    "\n",
    "üîÑ TRANSFORMATIONS:\n",
    "\"\"\"\n",
    "\n",
    "for pattern, count in transformation_patterns.items():\n",
    "    percentage = count / total_examples * 100 if total_examples > 0 else 0\n",
    "    report += f\"‚Ä¢ {pattern.title()}: {count} examples ({percentage:.1f}%)\\n\"\n",
    "\n",
    "size_rel_counts = Counter(stats['input_output_size_relations'])\n",
    "report += \"\\nüîç SIZE RELATIONSHIPS:\\n\"\n",
    "for rel, count in size_rel_counts.items():\n",
    "    percentage = count / len(stats['input_output_size_relations']) * 100\n",
    "    report += f\"‚Ä¢ {rel.title()}: {count} examples ({percentage:.1f}%)\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "üí° KEY INSIGHTS:\n",
    "‚Ä¢ Grid sizes vary significantly, requiring flexible architectures\n",
    "‚Ä¢ Color usage is uneven - black (0) typically most common\n",
    "‚Ä¢ Most transformations are complex, suggesting need for sophisticated models\n",
    "‚Ä¢ Size relationships are important - many tasks maintain grid dimensions\n",
    "\n",
    "üéØ IMPLICATIONS FOR MODEL DESIGN:\n",
    "‚Ä¢ Multi-scale processing needed for variable grid sizes\n",
    "‚Ä¢ Color-aware representations important\n",
    "‚Ä¢ Spatial reasoning capabilities essential\n",
    "‚Ä¢ Pattern recognition across different scales required\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report to file\n",
    "try:\n",
    "    import os\n",
    "    os.makedirs('../reports', exist_ok=True)\n",
    "    with open('../reports/exploration_report.txt', 'w') as f:\n",
    "        f.write(report)\n",
    "    print(\"\\nüíæ Report saved to ../reports/exploration_report.txt\")\n",
    "except:\n",
    "    print(\"\\n‚ö† Could not save report to file (directory may not exist)\")\n",
    "\n",
    "print(\"\\nüéâ Exploration complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
